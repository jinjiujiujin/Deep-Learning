{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实践：UNet论文中的经典任务——医学图像分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据个数： 30\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n",
      "torch.Size([2, 1, 512, 512])\n"
     ]
    }
   ],
   "source": [
    "# 加载数据\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class ISBI_Loader(Dataset):\n",
    "    def __init__(self, data_path):\n",
    "        # 读取所有data_path下的图片\n",
    "        self.data_path = data_path\n",
    "        self.imgs_path = glob.glob(os.path.join(data_path, 'image/*.png'))\n",
    "\n",
    "    def augment(self, image, flipCode):\n",
    "        # 使用cv2.flip进行数据增强(使数据变多)\n",
    "        # flipCode为1水平翻转，0垂直翻转， -1水平+垂直\n",
    "        flip = cv2.flip(image, flipCode)\n",
    "        return flip\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.imgs_path[index]\n",
    "        label_path = image_path.replace('image', 'label')\n",
    "        \n",
    "        image = cv2.imread(image_path)\n",
    "        label = cv2.imread(label_path)\n",
    "        # 将数据转为单通道的图片\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        label = cv2.cvtColor(label, cv2.COLOR_BGR2GRAY)\n",
    "        image = image.reshape(1, image.shape[0], image.shape[1])\n",
    "        label = label.reshape(1, label.shape[0], label.shape[1])\n",
    "        # 处理标签，范围缩至0-1\n",
    "        if label.max()>1:\n",
    "            label = label/255\n",
    "        # 随机进行数据增强，为2时不做处理\n",
    "        flipCode = random.choice([-1,0,1,2])\n",
    "        if flipCode !=2:\n",
    "            image = self.augment(image, flipCode)\n",
    "            label = self.augment(label, flipCode)\n",
    "        return image, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imgs_path)\n",
    "\n",
    "isbi_dataset = ISBI_Loader(r\"D:\\_workPlace\\Book\\AI\\CV\\UNet\\data\\train\")#路径必须是全英文\n",
    "print(\"数据个数：\", len(isbi_dataset))\n",
    "train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                           batch_size=2,\n",
    "                                           shuffle=True)\n",
    "for image, label in train_loader:\n",
    "    print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNet模型，相比UNet文件中，对它进行了微调，使得网络的输出尺寸刚好等于图片的输入尺寸\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "    \n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels//2, in_channels//2, kernel_size=2,stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # 特征的融合\n",
    "        diffY = torch.tensor([x2.size()[2]-x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3]-x1.size()[3]])\n",
    "        # 填充\n",
    "        x1 = F.pad(x1, [diffX//2, diffX-diffX//2,\n",
    "                        diffY//2, diffY-diffY//2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "        \n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        self.down4 = Down(512, 512)\n",
    "        self.up1 = Up(1024, 256, bilinear)\n",
    "        self.up2 = Up(512, 128, bilinear)\n",
    "        self.up3 = Up(256, 64, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "from torch import optim\n",
    "def train_net(net, device, data_path, epochs=40, batch_size=1, lr=0.00001):\n",
    "    # 加载训练集\n",
    "    isbi_dataset = ISBI_Loader(data_path)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=isbi_dataset,\n",
    "                                               batch_size=2,\n",
    "                                               shuffle=True)\n",
    "    # 定义RMSprop算法\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr, weight_decay=1e-8, momentum=0.9)# weight_decay和momentum的详细介绍https://blog.csdn.net/xuxiatian/article/details/72771609?locationNum=7&fps=1\n",
    "    # 定义Loss算法 BCEWithLogitsLoss比较高级的自适应优化算法\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    # best_loss统计，初始化为正无穷\n",
    "    best_loss = float('inf')\n",
    "    # 训练epochs次\n",
    "    for epoch in range(epochs):\n",
    "        net.train()\n",
    "        print('epoch ', epoch)\n",
    "        for image, label in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            # 将数据拷贝到device中\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            label = label.to(device=device, dtype=torch.float32)\n",
    "            # 使用网络参数，输出预测结果\n",
    "            pred = net(image)\n",
    "            loss = criterion(pred, label)\n",
    "            print('Loss/train', loss.item())\n",
    "            # 保存loss值最小的网络参数\n",
    "            if loss<best_loss:\n",
    "                best_loss = loss\n",
    "                torch.save(net.state_dict(), r'D:\\_workPlace\\Book\\AI\\CV\\UNet\\best_model.pth')\n",
    "            #更新参数\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss/train 0.844826877117157\n",
      "Loss/train 0.7857764959335327\n",
      "Loss/train 0.7505689263343811\n",
      "Loss/train 0.7023769617080688\n",
      "Loss/train 0.7376537919044495\n",
      "Loss/train 0.6869902014732361\n",
      "Loss/train 0.6566864848136902\n",
      "Loss/train 0.6249339580535889\n",
      "Loss/train 0.6147798299789429\n",
      "Loss/train 0.6211022734642029\n",
      "Loss/train 0.6024956703186035\n",
      "Loss/train 0.5652669668197632\n",
      "Loss/train 0.5660802721977234\n",
      "Loss/train 0.5444195866584778\n",
      "Loss/train 0.5884251594543457\n",
      "Loss/train 0.5384031534194946\n",
      "Loss/train 0.5142563581466675\n",
      "Loss/train 0.4962066411972046\n",
      "Loss/train 0.491624116897583\n",
      "Loss/train 0.464009553194046\n",
      "Loss/train 0.4441261887550354\n",
      "Loss/train 0.46011587977409363\n",
      "Loss/train 0.4961172640323639\n",
      "Loss/train 0.4512881338596344\n",
      "Loss/train 0.4315793514251709\n",
      "Loss/train 0.4352658689022064\n",
      "Loss/train 0.4426954388618469\n",
      "Loss/train 0.43671542406082153\n",
      "Loss/train 0.43543702363967896\n",
      "Loss/train 0.4104059934616089\n",
      "Loss/train 0.41676610708236694\n",
      "Loss/train 0.4256676435470581\n",
      "Loss/train 0.41161826252937317\n",
      "Loss/train 0.4499671459197998\n",
      "Loss/train 0.4304194450378418\n",
      "Loss/train 0.41211652755737305\n",
      "Loss/train 0.4087805151939392\n",
      "Loss/train 0.3958130478858948\n",
      "Loss/train 0.39378875494003296\n",
      "Loss/train 0.40143752098083496\n",
      "Loss/train 0.40153932571411133\n",
      "Loss/train 0.39729875326156616\n",
      "Loss/train 0.41195613145828247\n",
      "Loss/train 0.3793147802352905\n",
      "Loss/train 0.3825485408306122\n",
      "Loss/train 0.3951314687728882\n",
      "Loss/train 0.3724908232688904\n",
      "Loss/train 0.38854217529296875\n",
      "Loss/train 0.3795523941516876\n",
      "Loss/train 0.37641188502311707\n",
      "Loss/train 0.39575716853141785\n",
      "Loss/train 0.36306414008140564\n",
      "Loss/train 0.37350940704345703\n",
      "Loss/train 0.38164886832237244\n",
      "Loss/train 0.38158485293388367\n",
      "Loss/train 0.37057429552078247\n",
      "Loss/train 0.3759153485298157\n",
      "Loss/train 0.36875829100608826\n",
      "Loss/train 0.3712872564792633\n",
      "Loss/train 0.3595430850982666\n",
      "Loss/train 0.3605620861053467\n",
      "Loss/train 0.3690955638885498\n",
      "Loss/train 0.3513733148574829\n",
      "Loss/train 0.36479151248931885\n",
      "Loss/train 0.3548174202442169\n",
      "Loss/train 0.36675816774368286\n",
      "Loss/train 0.3675248920917511\n",
      "Loss/train 0.38040316104888916\n",
      "Loss/train 0.35691335797309875\n",
      "Loss/train 0.36334505677223206\n",
      "Loss/train 0.35372012853622437\n",
      "Loss/train 0.3592317998409271\n",
      "Loss/train 0.3572356104850769\n",
      "Loss/train 0.354101300239563\n",
      "Loss/train 0.34476175904273987\n",
      "Loss/train 0.3623872995376587\n",
      "Loss/train 0.34669673442840576\n",
      "Loss/train 0.3588559925556183\n",
      "Loss/train 0.364124059677124\n",
      "Loss/train 0.33487021923065186\n",
      "Loss/train 0.3472135663032532\n",
      "Loss/train 0.3561229705810547\n",
      "Loss/train 0.3487190306186676\n",
      "Loss/train 0.349364310503006\n",
      "Loss/train 0.3522690534591675\n",
      "Loss/train 0.34522542357444763\n",
      "Loss/train 0.3516318202018738\n",
      "Loss/train 0.34643328189849854\n",
      "Loss/train 0.33288314938545227\n",
      "Loss/train 0.3416304886341095\n",
      "Loss/train 0.32996177673339844\n",
      "Loss/train 0.33969807624816895\n",
      "Loss/train 0.3430495858192444\n",
      "Loss/train 0.3511936068534851\n",
      "Loss/train 0.3402174711227417\n",
      "Loss/train 0.3535204827785492\n",
      "Loss/train 0.34865525364875793\n",
      "Loss/train 0.336142361164093\n",
      "Loss/train 0.3331540822982788\n",
      "Loss/train 0.3643536865711212\n",
      "Loss/train 0.32170847058296204\n",
      "Loss/train 0.33091703057289124\n",
      "Loss/train 0.3390612006187439\n",
      "Loss/train 0.34388041496276855\n",
      "Loss/train 0.317221075296402\n",
      "Loss/train 0.34727612137794495\n",
      "Loss/train 0.33238279819488525\n",
      "Loss/train 0.32819226384162903\n",
      "Loss/train 0.3187689185142517\n",
      "Loss/train 0.3270220458507538\n",
      "Loss/train 0.3254845142364502\n",
      "Loss/train 0.32883766293525696\n",
      "Loss/train 0.32379958033561707\n",
      "Loss/train 0.3358313739299774\n",
      "Loss/train 0.32649606466293335\n",
      "Loss/train 0.32359325885772705\n",
      "Loss/train 0.3223041296005249\n",
      "Loss/train 0.3397936522960663\n",
      "Loss/train 0.3207953870296478\n",
      "Loss/train 0.32966914772987366\n",
      "Loss/train 0.33323854207992554\n",
      "Loss/train 0.31710511445999146\n",
      "Loss/train 0.3225616216659546\n",
      "Loss/train 0.3223423957824707\n",
      "Loss/train 0.3118727505207062\n",
      "Loss/train 0.32286009192466736\n",
      "Loss/train 0.31403785943984985\n",
      "Loss/train 0.30732667446136475\n",
      "Loss/train 0.32710275053977966\n",
      "Loss/train 0.3211316764354706\n",
      "Loss/train 0.33864638209342957\n",
      "Loss/train 0.31567299365997314\n",
      "Loss/train 0.32894355058670044\n",
      "Loss/train 0.33146142959594727\n",
      "Loss/train 0.30670100450515747\n",
      "Loss/train 0.33503860235214233\n",
      "Loss/train 0.30868712067604065\n",
      "Loss/train 0.30973508954048157\n",
      "Loss/train 0.3131566643714905\n",
      "Loss/train 0.3130846917629242\n",
      "Loss/train 0.2977973222732544\n",
      "Loss/train 0.304818332195282\n",
      "Loss/train 0.3113987445831299\n",
      "Loss/train 0.32948318123817444\n",
      "Loss/train 0.2965441942214966\n",
      "Loss/train 0.3225618600845337\n",
      "Loss/train 0.3293537199497223\n",
      "Loss/train 0.31416788697242737\n",
      "Loss/train 0.3064151406288147\n",
      "Loss/train 0.3097175359725952\n",
      "Loss/train 0.3148523271083832\n",
      "Loss/train 0.31294798851013184\n",
      "Loss/train 0.31013262271881104\n",
      "Loss/train 0.2967465817928314\n",
      "Loss/train 0.3070617616176605\n",
      "Loss/train 0.3125004768371582\n",
      "Loss/train 0.32129043340682983\n",
      "Loss/train 0.30881813168525696\n",
      "Loss/train 0.3072621822357178\n",
      "Loss/train 0.3076898753643036\n",
      "Loss/train 0.3118188679218292\n",
      "Loss/train 0.30290064215660095\n",
      "Loss/train 0.29558858275413513\n",
      "Loss/train 0.295835018157959\n",
      "Loss/train 0.3033531606197357\n",
      "Loss/train 0.2966291606426239\n",
      "Loss/train 0.3142637312412262\n",
      "Loss/train 0.31122371554374695\n",
      "Loss/train 0.3026133179664612\n",
      "Loss/train 0.29171833395957947\n",
      "Loss/train 0.3039249777793884\n",
      "Loss/train 0.32211220264434814\n",
      "Loss/train 0.2998846769332886\n",
      "Loss/train 0.2841985523700714\n",
      "Loss/train 0.2930457293987274\n",
      "Loss/train 0.29765111207962036\n",
      "Loss/train 0.3001546263694763\n",
      "Loss/train 0.302950918674469\n",
      "Loss/train 0.2933310866355896\n",
      "Loss/train 0.29804837703704834\n",
      "Loss/train 0.29881060123443604\n",
      "Loss/train 0.30236726999282837\n",
      "Loss/train 0.2990267276763916\n",
      "Loss/train 0.29459646344184875\n",
      "Loss/train 0.28476953506469727\n",
      "Loss/train 0.30600666999816895\n",
      "Loss/train 0.30568015575408936\n",
      "Loss/train 0.28091225028038025\n",
      "Loss/train 0.31313133239746094\n",
      "Loss/train 0.2907710373401642\n",
      "Loss/train 0.28918880224227905\n",
      "Loss/train 0.2945408821105957\n",
      "Loss/train 0.28696709871292114\n",
      "Loss/train 0.2925945520401001\n",
      "Loss/train 0.30109068751335144\n",
      "Loss/train 0.30206745862960815\n",
      "Loss/train 0.29483750462532043\n",
      "Loss/train 0.2940962016582489\n",
      "Loss/train 0.28594493865966797\n",
      "Loss/train 0.29840150475502014\n",
      "Loss/train 0.30053529143333435\n",
      "Loss/train 0.2819511294364929\n",
      "Loss/train 0.2844543755054474\n",
      "Loss/train 0.2821616530418396\n",
      "Loss/train 0.28380003571510315\n",
      "Loss/train 0.28807321190834045\n",
      "Loss/train 0.29974400997161865\n",
      "Loss/train 0.2898906171321869\n",
      "Loss/train 0.2833510637283325\n",
      "Loss/train 0.3011587858200073\n",
      "Loss/train 0.2786462903022766\n",
      "Loss/train 0.2819754183292389\n",
      "Loss/train 0.2877882719039917\n",
      "Loss/train 0.2821003794670105\n",
      "Loss/train 0.2878751754760742\n",
      "Loss/train 0.2832205593585968\n",
      "Loss/train 0.2904229462146759\n",
      "Loss/train 0.27956080436706543\n",
      "Loss/train 0.2743210792541504\n",
      "Loss/train 0.29286253452301025\n",
      "Loss/train 0.30070197582244873\n",
      "Loss/train 0.28843316435813904\n",
      "Loss/train 0.2814830243587494\n",
      "Loss/train 0.2759318947792053\n",
      "Loss/train 0.2832958996295929\n",
      "Loss/train 0.2762911915779114\n",
      "Loss/train 0.2814798355102539\n",
      "Loss/train 0.27319374680519104\n",
      "Loss/train 0.27334919571876526\n",
      "Loss/train 0.27358266711235046\n",
      "Loss/train 0.2860501706600189\n",
      "Loss/train 0.2770475447177887\n",
      "Loss/train 0.26900532841682434\n",
      "Loss/train 0.27804094552993774\n",
      "Loss/train 0.3016458749771118\n",
      "Loss/train 0.2710689604282379\n",
      "Loss/train 0.2836076021194458\n",
      "Loss/train 0.280856728553772\n",
      "Loss/train 0.2711273431777954\n",
      "Loss/train 0.3103744685649872\n",
      "Loss/train 0.2646333873271942\n",
      "Loss/train 0.2924363315105438\n",
      "Loss/train 0.2680014967918396\n",
      "Loss/train 0.27190855145454407\n",
      "Loss/train 0.2730926275253296\n",
      "Loss/train 0.2780666649341583\n",
      "Loss/train 0.2678941488265991\n",
      "Loss/train 0.2715035676956177\n",
      "Loss/train 0.2796160876750946\n",
      "Loss/train 0.2978520393371582\n",
      "Loss/train 0.27147606015205383\n",
      "Loss/train 0.27966728806495667\n",
      "Loss/train 0.2706019878387451\n",
      "Loss/train 0.27415749430656433\n",
      "Loss/train 0.28694576025009155\n",
      "Loss/train 0.2755550742149353\n",
      "Loss/train 0.27429288625717163\n",
      "Loss/train 0.28045031428337097\n",
      "Loss/train 0.26151472330093384\n",
      "Loss/train 0.2747938930988312\n",
      "Loss/train 0.2687954306602478\n",
      "Loss/train 0.2703704833984375\n",
      "Loss/train 0.28284451365470886\n",
      "Loss/train 0.26218581199645996\n",
      "Loss/train 0.2724772095680237\n",
      "Loss/train 0.2699286639690399\n",
      "Loss/train 0.2905716300010681\n",
      "Loss/train 0.2690325677394867\n",
      "Loss/train 0.2583179175853729\n",
      "Loss/train 0.2718062400817871\n",
      "Loss/train 0.2681053876876831\n",
      "Loss/train 0.2680492103099823\n",
      "Loss/train 0.2674838602542877\n",
      "Loss/train 0.26759713888168335\n",
      "Loss/train 0.2850341498851776\n",
      "Loss/train 0.2779625356197357\n",
      "Loss/train 0.2665109634399414\n",
      "Loss/train 0.26560890674591064\n",
      "Loss/train 0.2576245069503784\n",
      "Loss/train 0.2618541717529297\n",
      "Loss/train 0.2502874732017517\n",
      "Loss/train 0.25487515330314636\n",
      "Loss/train 0.2714162766933441\n",
      "Loss/train 0.27156761288642883\n",
      "Loss/train 0.2582092583179474\n",
      "Loss/train 0.2620922327041626\n",
      "Loss/train 0.25783371925354004\n",
      "Loss/train 0.27408674359321594\n",
      "Loss/train 0.266867458820343\n",
      "Loss/train 0.26090437173843384\n",
      "Loss/train 0.271354079246521\n",
      "Loss/train 0.26208198070526123\n",
      "Loss/train 0.26702386140823364\n",
      "Loss/train 0.2618008255958557\n",
      "Loss/train 0.25941789150238037\n",
      "Loss/train 0.2602798342704773\n",
      "Loss/train 0.2638995051383972\n",
      "Loss/train 0.2777518033981323\n",
      "Loss/train 0.25778883695602417\n",
      "Loss/train 0.2631528377532959\n",
      "Loss/train 0.26071611046791077\n",
      "Loss/train 0.25840431451797485\n",
      "Loss/train 0.2498430609703064\n",
      "Loss/train 0.2612386643886566\n",
      "Loss/train 0.2484370768070221\n",
      "Loss/train 0.24078711867332458\n",
      "Loss/train 0.25946515798568726\n",
      "Loss/train 0.2589593529701233\n",
      "Loss/train 0.25289851427078247\n",
      "Loss/train 0.24827101826667786\n",
      "Loss/train 0.2632008194923401\n",
      "Loss/train 0.25544407963752747\n",
      "Loss/train 0.2540585994720459\n",
      "Loss/train 0.26904815435409546\n",
      "Loss/train 0.2548336088657379\n",
      "Loss/train 0.24879534542560577\n",
      "Loss/train 0.2472561001777649\n",
      "Loss/train 0.24777032434940338\n",
      "Loss/train 0.24490995705127716\n",
      "Loss/train 0.2502284049987793\n",
      "Loss/train 0.2686728239059448\n",
      "Loss/train 0.2649889588356018\n",
      "Loss/train 0.25039780139923096\n",
      "Loss/train 0.24810253083705902\n",
      "Loss/train 0.25506722927093506\n",
      "Loss/train 0.24194800853729248\n",
      "Loss/train 0.2441560924053192\n",
      "Loss/train 0.24520298838615417\n",
      "Loss/train 0.26138216257095337\n",
      "Loss/train 0.24829360842704773\n",
      "Loss/train 0.2446635514497757\n",
      "Loss/train 0.24221765995025635\n",
      "Loss/train 0.24663880467414856\n",
      "Loss/train 0.24875637888908386\n",
      "Loss/train 0.25409114360809326\n",
      "Loss/train 0.24137118458747864\n",
      "Loss/train 0.2530171871185303\n",
      "Loss/train 0.2525773048400879\n",
      "Loss/train 0.2420792281627655\n",
      "Loss/train 0.25030189752578735\n",
      "Loss/train 0.24360421299934387\n",
      "Loss/train 0.2549782991409302\n",
      "Loss/train 0.26364925503730774\n",
      "Loss/train 0.23845970630645752\n",
      "Loss/train 0.24603727459907532\n",
      "Loss/train 0.24911516904830933\n",
      "Loss/train 0.23566147685050964\n",
      "Loss/train 0.2422139197587967\n",
      "Loss/train 0.246256023645401\n",
      "Loss/train 0.24312451481819153\n",
      "Loss/train 0.24821433424949646\n",
      "Loss/train 0.24673058092594147\n",
      "Loss/train 0.23442184925079346\n",
      "Loss/train 0.24059626460075378\n",
      "Loss/train 0.23923572897911072\n",
      "Loss/train 0.23618240654468536\n",
      "Loss/train 0.23061221837997437\n",
      "Loss/train 0.2390880286693573\n",
      "Loss/train 0.26372435688972473\n",
      "Loss/train 0.2544349431991577\n",
      "Loss/train 0.2539815902709961\n",
      "Loss/train 0.2455674260854721\n",
      "Loss/train 0.24147318303585052\n",
      "Loss/train 0.23693715035915375\n",
      "Loss/train 0.26082590222358704\n",
      "Loss/train 0.24704650044441223\n",
      "Loss/train 0.23170220851898193\n",
      "Loss/train 0.23257508873939514\n",
      "Loss/train 0.24069064855575562\n",
      "Loss/train 0.2397482693195343\n",
      "Loss/train 0.2559494078159332\n",
      "Loss/train 0.23458656668663025\n",
      "Loss/train 0.23313994705677032\n",
      "Loss/train 0.2414301037788391\n",
      "Loss/train 0.2547340989112854\n",
      "Loss/train 0.2367181032896042\n",
      "Loss/train 0.25525885820388794\n",
      "Loss/train 0.24019043147563934\n",
      "Loss/train 0.23472914099693298\n",
      "Loss/train 0.23829582333564758\n",
      "Loss/train 0.23675361275672913\n",
      "Loss/train 0.25473859906196594\n",
      "Loss/train 0.24913622438907623\n",
      "Loss/train 0.23724453151226044\n",
      "Loss/train 0.24034148454666138\n",
      "Loss/train 0.2343887984752655\n",
      "Loss/train 0.23737986385822296\n",
      "Loss/train 0.24154558777809143\n",
      "Loss/train 0.22879764437675476\n",
      "Loss/train 0.23785100877285004\n",
      "Loss/train 0.23264220356941223\n",
      "Loss/train 0.21721340715885162\n",
      "Loss/train 0.22944101691246033\n",
      "Loss/train 0.23097026348114014\n",
      "Loss/train 0.23365691304206848\n",
      "Loss/train 0.22689583897590637\n",
      "Loss/train 0.23018473386764526\n",
      "Loss/train 0.22081315517425537\n",
      "Loss/train 0.2334301471710205\n",
      "Loss/train 0.24961647391319275\n",
      "Loss/train 0.24785175919532776\n",
      "Loss/train 0.23176342248916626\n",
      "Loss/train 0.24247397482395172\n",
      "Loss/train 0.2287803441286087\n",
      "Loss/train 0.24511273205280304\n",
      "Loss/train 0.2289230227470398\n",
      "Loss/train 0.2364976555109024\n",
      "Loss/train 0.2308494597673416\n",
      "Loss/train 0.227362722158432\n",
      "Loss/train 0.23750823736190796\n",
      "Loss/train 0.24562345445156097\n",
      "Loss/train 0.22304950654506683\n",
      "Loss/train 0.21858583390712738\n",
      "Loss/train 0.23314881324768066\n",
      "Loss/train 0.2403169572353363\n",
      "Loss/train 0.23434773087501526\n",
      "Loss/train 0.22637486457824707\n",
      "Loss/train 0.2211226224899292\n",
      "Loss/train 0.22599783539772034\n",
      "Loss/train 0.2190333902835846\n",
      "Loss/train 0.22740069031715393\n",
      "Loss/train 0.2388935387134552\n",
      "Loss/train 0.22046339511871338\n",
      "Loss/train 0.22650860249996185\n",
      "Loss/train 0.2265477031469345\n",
      "Loss/train 0.23678980767726898\n",
      "Loss/train 0.22062601149082184\n",
      "Loss/train 0.23302188515663147\n",
      "Loss/train 0.23162558674812317\n",
      "Loss/train 0.21393370628356934\n",
      "Loss/train 0.23099157214164734\n",
      "Loss/train 0.22434154152870178\n",
      "Loss/train 0.22135013341903687\n",
      "Loss/train 0.22892586886882782\n",
      "Loss/train 0.227397620677948\n",
      "Loss/train 0.22517883777618408\n",
      "Loss/train 0.2338305115699768\n",
      "Loss/train 0.2176695615053177\n",
      "Loss/train 0.21983270347118378\n",
      "Loss/train 0.24832184612751007\n",
      "Loss/train 0.21712757647037506\n",
      "Loss/train 0.21917089819908142\n",
      "Loss/train 0.21739163994789124\n",
      "Loss/train 0.21792905032634735\n",
      "Loss/train 0.21950918436050415\n",
      "Loss/train 0.22234292328357697\n",
      "Loss/train 0.22219127416610718\n",
      "Loss/train 0.21597838401794434\n",
      "Loss/train 0.22352519631385803\n",
      "Loss/train 0.24171601235866547\n",
      "Loss/train 0.21102456748485565\n",
      "Loss/train 0.2283235788345337\n",
      "Loss/train 0.2132008671760559\n",
      "Loss/train 0.23076921701431274\n",
      "Loss/train 0.21771860122680664\n",
      "Loss/train 0.2169608771800995\n",
      "Loss/train 0.21394163370132446\n",
      "Loss/train 0.23795372247695923\n",
      "Loss/train 0.21237534284591675\n",
      "Loss/train 0.2258351743221283\n",
      "Loss/train 0.22511696815490723\n",
      "Loss/train 0.22812440991401672\n",
      "Loss/train 0.221840500831604\n",
      "Loss/train 0.21673069894313812\n",
      "Loss/train 0.22376690804958344\n",
      "Loss/train 0.21911770105361938\n",
      "Loss/train 0.20840230584144592\n",
      "Loss/train 0.21241523325443268\n",
      "Loss/train 0.21665418148040771\n",
      "Loss/train 0.2226908951997757\n",
      "Loss/train 0.21590234339237213\n",
      "Loss/train 0.21493183076381683\n",
      "Loss/train 0.2110007405281067\n",
      "Loss/train 0.21280261874198914\n",
      "Loss/train 0.2102319747209549\n",
      "Loss/train 0.21640928089618683\n",
      "Loss/train 0.21135297417640686\n",
      "Loss/train 0.20651036500930786\n",
      "Loss/train 0.21610446274280548\n",
      "Loss/train 0.23233741521835327\n",
      "Loss/train 0.20411062240600586\n",
      "Loss/train 0.2300148457288742\n",
      "Loss/train 0.20676961541175842\n",
      "Loss/train 0.21652691066265106\n",
      "Loss/train 0.2094394713640213\n",
      "Loss/train 0.21281319856643677\n",
      "Loss/train 0.21729499101638794\n",
      "Loss/train 0.209832102060318\n",
      "Loss/train 0.22467440366744995\n",
      "Loss/train 0.21525388956069946\n",
      "Loss/train 0.20681318640708923\n",
      "Loss/train 0.21257472038269043\n",
      "Loss/train 0.20923228561878204\n",
      "Loss/train 0.2142091691493988\n",
      "Loss/train 0.21676616370677948\n",
      "Loss/train 0.20053088665008545\n",
      "Loss/train 0.2099909633398056\n",
      "Loss/train 0.20832663774490356\n",
      "Loss/train 0.20636887848377228\n",
      "Loss/train 0.20565904676914215\n",
      "Loss/train 0.2088945358991623\n",
      "Loss/train 0.22280560433864594\n",
      "Loss/train 0.21591655910015106\n",
      "Loss/train 0.20018064975738525\n",
      "Loss/train 0.21652105450630188\n",
      "Loss/train 0.2045910656452179\n",
      "Loss/train 0.2217429131269455\n",
      "Loss/train 0.21234369277954102\n",
      "Loss/train 0.2071661651134491\n",
      "Loss/train 0.22585541009902954\n",
      "Loss/train 0.20656777918338776\n",
      "Loss/train 0.20514650642871857\n",
      "Loss/train 0.21413323283195496\n",
      "Loss/train 0.20893007516860962\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c820ee91e3f2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"D:\\_workPlace\\Book\\AI\\CV\\UNet\\data\\train\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-0c9e4790de71>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, device, data_path, epochs, batch_size, lr)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[1;31m# 使用网络参数，输出预测结果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss/train'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e9fa2f250f83>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[0mx4\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdown3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[0mx5\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdown4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e9fa2f250f83>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x1, x2)\u001b[0m\n\u001b[0;32m     44\u001b[0m                         diffY//2, diffY-diffY//2])\n\u001b[0;32m     45\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mOutConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e9fa2f250f83>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     15\u001b[0m         )\n\u001b[0;32m     16\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble_conv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mDown\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    348\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    349\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 350\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = UNet(n_channels=1, n_classes=1)\n",
    "net.to(device=device)\n",
    "data_path=r\"D:\\_workPlace\\Book\\AI\\CV\\UNet\\data\\train\"\n",
    "train_net(net, device, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0\n",
      "Loss/train 0.2153027057647705\n",
      "Loss/train 0.2036285400390625\n",
      "Loss/train 0.2252168208360672\n",
      "Loss/train 0.22698403894901276\n",
      "Loss/train 0.23495785892009735\n",
      "Loss/train 0.22438110411167145\n",
      "Loss/train 0.22229404747486115\n",
      "Loss/train 0.23490528762340546\n",
      "Loss/train 0.232426255941391\n",
      "Loss/train 0.2421875149011612\n",
      "Loss/train 0.24110187590122223\n",
      "Loss/train 0.2219175547361374\n",
      "Loss/train 0.22014302015304565\n",
      "Loss/train 0.225480318069458\n",
      "Loss/train 0.2266569435596466\n",
      "epoch  1\n",
      "Loss/train 0.2102348953485489\n",
      "Loss/train 0.21975284814834595\n",
      "Loss/train 0.21820513904094696\n",
      "Loss/train 0.23151665925979614\n",
      "Loss/train 0.2126106172800064\n",
      "Loss/train 0.21045231819152832\n",
      "Loss/train 0.2308168113231659\n",
      "Loss/train 0.21440434455871582\n",
      "Loss/train 0.21008555591106415\n",
      "Loss/train 0.20876458287239075\n",
      "Loss/train 0.23725970089435577\n",
      "Loss/train 0.21021120250225067\n",
      "Loss/train 0.21051812171936035\n",
      "Loss/train 0.2007526010274887\n",
      "Loss/train 0.21985162794589996\n",
      "epoch  2\n",
      "Loss/train 0.22633305191993713\n",
      "Loss/train 0.2322261780500412\n",
      "Loss/train 0.2103009968996048\n",
      "Loss/train 0.20608410239219666\n",
      "Loss/train 0.21166014671325684\n",
      "Loss/train 0.21780918538570404\n",
      "Loss/train 0.2065654695034027\n",
      "Loss/train 0.1959347128868103\n",
      "Loss/train 0.20492178201675415\n",
      "Loss/train 0.20553900301456451\n",
      "Loss/train 0.2008756846189499\n",
      "Loss/train 0.19608211517333984\n",
      "Loss/train 0.19376568496227264\n",
      "Loss/train 0.2195873111486435\n",
      "Loss/train 0.20224186778068542\n",
      "epoch  3\n",
      "Loss/train 0.19241592288017273\n",
      "Loss/train 0.20033320784568787\n",
      "Loss/train 0.2181513011455536\n",
      "Loss/train 0.1852414309978485\n",
      "Loss/train 0.20579025149345398\n",
      "Loss/train 0.19584892690181732\n",
      "Loss/train 0.21349653601646423\n",
      "Loss/train 0.22460021078586578\n",
      "Loss/train 0.21393069624900818\n",
      "Loss/train 0.19462430477142334\n",
      "Loss/train 0.20374718308448792\n",
      "Loss/train 0.20479798316955566\n",
      "Loss/train 0.20099438726902008\n",
      "Loss/train 0.19778212904930115\n",
      "Loss/train 0.19357836246490479\n",
      "epoch  4\n",
      "Loss/train 0.20145796239376068\n",
      "Loss/train 0.19027316570281982\n",
      "Loss/train 0.1904539316892624\n",
      "Loss/train 0.2115190178155899\n",
      "Loss/train 0.1858474761247635\n",
      "Loss/train 0.19318810105323792\n",
      "Loss/train 0.21175506711006165\n",
      "Loss/train 0.19301080703735352\n",
      "Loss/train 0.19086351990699768\n",
      "Loss/train 0.1968560814857483\n",
      "Loss/train 0.19772356748580933\n",
      "Loss/train 0.19515128433704376\n",
      "Loss/train 0.19214090704917908\n",
      "Loss/train 0.20057706534862518\n",
      "Loss/train 0.18326961994171143\n",
      "epoch  5\n",
      "Loss/train 0.18451982736587524\n",
      "Loss/train 0.19212771952152252\n",
      "Loss/train 0.19414587318897247\n",
      "Loss/train 0.19665823876857758\n",
      "Loss/train 0.20734697580337524\n",
      "Loss/train 0.1945517659187317\n",
      "Loss/train 0.17965030670166016\n",
      "Loss/train 0.18943127989768982\n",
      "Loss/train 0.1868833750486374\n",
      "Loss/train 0.19937361776828766\n",
      "Loss/train 0.18099242448806763\n",
      "Loss/train 0.1810799539089203\n",
      "Loss/train 0.18484121561050415\n",
      "Loss/train 0.17828302085399628\n",
      "Loss/train 0.19156494736671448\n",
      "epoch  6\n",
      "Loss/train 0.1895095407962799\n",
      "Loss/train 0.19251951575279236\n",
      "Loss/train 0.1805267333984375\n",
      "Loss/train 0.17592933773994446\n",
      "Loss/train 0.1769419014453888\n",
      "Loss/train 0.19806808233261108\n",
      "Loss/train 0.18340040743350983\n",
      "Loss/train 0.1789412945508957\n",
      "Loss/train 0.19005675613880157\n",
      "Loss/train 0.18712283670902252\n",
      "Loss/train 0.18297894299030304\n",
      "Loss/train 0.20090997219085693\n",
      "Loss/train 0.18036194145679474\n",
      "Loss/train 0.19513869285583496\n",
      "Loss/train 0.1885681450366974\n",
      "epoch  7\n",
      "Loss/train 0.19744853675365448\n",
      "Loss/train 0.17913351953029633\n",
      "Loss/train 0.1888720542192459\n",
      "Loss/train 0.1793765127658844\n",
      "Loss/train 0.1805483102798462\n",
      "Loss/train 0.17855221033096313\n",
      "Loss/train 0.18704858422279358\n",
      "Loss/train 0.20217636227607727\n",
      "Loss/train 0.17513418197631836\n",
      "Loss/train 0.16746731102466583\n",
      "Loss/train 0.17563584446907043\n",
      "Loss/train 0.17599114775657654\n",
      "Loss/train 0.1758565902709961\n",
      "Loss/train 0.18100178241729736\n",
      "Loss/train 0.20818474888801575\n",
      "epoch  8\n",
      "Loss/train 0.1705249696969986\n",
      "Loss/train 0.17562708258628845\n",
      "Loss/train 0.17707210779190063\n",
      "Loss/train 0.18844762444496155\n",
      "Loss/train 0.17639723420143127\n",
      "Loss/train 0.1895885318517685\n",
      "Loss/train 0.18539690971374512\n",
      "Loss/train 0.16658078134059906\n",
      "Loss/train 0.18487152457237244\n",
      "Loss/train 0.16773366928100586\n",
      "Loss/train 0.1743258535861969\n",
      "Loss/train 0.1625680774450302\n",
      "Loss/train 0.1924661099910736\n",
      "Loss/train 0.17961148917675018\n",
      "Loss/train 0.17683790624141693\n",
      "epoch  9\n",
      "Loss/train 0.1759968400001526\n",
      "Loss/train 0.16885046660900116\n",
      "Loss/train 0.17069336771965027\n",
      "Loss/train 0.1630420833826065\n",
      "Loss/train 0.17867924273014069\n",
      "Loss/train 0.18120037019252777\n",
      "Loss/train 0.1775812804698944\n",
      "Loss/train 0.1742267608642578\n",
      "Loss/train 0.18705613911151886\n",
      "Loss/train 0.17175692319869995\n",
      "Loss/train 0.17383165657520294\n",
      "Loss/train 0.17530307173728943\n",
      "Loss/train 0.17333662509918213\n",
      "Loss/train 0.18150459229946136\n",
      "Loss/train 0.16815954446792603\n",
      "epoch  10\n",
      "Loss/train 0.1683170646429062\n",
      "Loss/train 0.18789252638816833\n",
      "Loss/train 0.16722992062568665\n",
      "Loss/train 0.1829603910446167\n",
      "Loss/train 0.1697687953710556\n",
      "Loss/train 0.18024402856826782\n",
      "Loss/train 0.16693611443042755\n",
      "Loss/train 0.18864791095256805\n",
      "Loss/train 0.1679849773645401\n",
      "Loss/train 0.17336975038051605\n",
      "Loss/train 0.16715200245380402\n",
      "Loss/train 0.1579674929380417\n",
      "Loss/train 0.16973254084587097\n",
      "Loss/train 0.18114116787910461\n",
      "Loss/train 0.191103994846344\n",
      "epoch  11\n",
      "Loss/train 0.17620530724525452\n",
      "Loss/train 0.1626834124326706\n",
      "Loss/train 0.17435263097286224\n",
      "Loss/train 0.1725098043680191\n",
      "Loss/train 0.17005355656147003\n",
      "Loss/train 0.17670762538909912\n",
      "Loss/train 0.18074944615364075\n",
      "Loss/train 0.16839799284934998\n",
      "Loss/train 0.1684836596250534\n",
      "Loss/train 0.18383421003818512\n",
      "Loss/train 0.1660834550857544\n",
      "Loss/train 0.16341477632522583\n",
      "Loss/train 0.16057144105434418\n",
      "Loss/train 0.16866914927959442\n",
      "Loss/train 0.16122587025165558\n",
      "epoch  12\n",
      "Loss/train 0.16613049805164337\n",
      "Loss/train 0.17179246246814728\n",
      "Loss/train 0.16201232373714447\n",
      "Loss/train 0.15691007673740387\n",
      "Loss/train 0.17687855660915375\n",
      "Loss/train 0.1736910492181778\n",
      "Loss/train 0.16382572054862976\n",
      "Loss/train 0.16021139919757843\n",
      "Loss/train 0.16187132894992828\n",
      "Loss/train 0.15950757265090942\n",
      "Loss/train 0.1528291255235672\n",
      "Loss/train 0.16481514275074005\n",
      "Loss/train 0.17466923594474792\n",
      "Loss/train 0.178978830575943\n",
      "Loss/train 0.17558111250400543\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-af085ace67e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr'D:\\_workPlace\\Book\\AI\\CV\\UNet\\best_model.pth'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"D:\\_workPlace\\Book\\AI\\CV\\UNet\\data\\train\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrain_net\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-2b968c0e0282>\u001b[0m in \u001b[0;36mtrain_net\u001b[1;34m(net, device, data_path, epochs, batch_size, lr)\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mr'D:\\_workPlace\\Book\\AI\\CV\\UNet\\best_model.pth'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[1;31m#更新参数\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Software\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 训练时间有点长，好在中途存了模型，大概还剩20epoch，可以明天重新加载模型。需要在上述代码中做修改。\n",
    "# 继续训练模型\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = UNet(n_channels=1, n_classes=1)\n",
    "net.to(device=device)\n",
    "net.load_state_dict(torch.load(r'D:\\_workPlace\\Book\\AI\\CV\\UNet\\best_model.pth', map_location=device))\n",
    "data_path=r\"D:\\_workPlace\\Book\\AI\\CV\\UNet\\data\\train\"\n",
    "train_net(net, device, data_path, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\0.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\1.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\10.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\11.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\12.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\13.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\14.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\15.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\16.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\17.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\18.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\19.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\2.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\20.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\21.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\22.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\23.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\24.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\25.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\26.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\27.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\28.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\29.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\3.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\4.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\5.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\6.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\7.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\8.png\n",
      "D:/_workPlace/Book/AI/CV/UNet/data/test\\9.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# 测试\n",
    "net.load_state_dict(torch.load(r'D:\\_workPlace\\Book\\AI\\CV\\UNet\\best_model.pth', map_location=device))\n",
    "# 测试模式\n",
    "net.eval()\n",
    "tests_path = glob.glob('D:/_workPlace/Book/AI/CV/UNet/data/test/*.png')\n",
    "for test_path in tests_path:\n",
    "    print(test_path)\n",
    "    save_res_path = test_path.split('.')[0]+'_res.png'\n",
    "    img = cv2.imread(test_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    # 转为batch为1，通道为1，大小为512*512的数组\n",
    "    img = img.reshape(1, 1, img.shape[0], img.shape[1])\n",
    "    img_tensor = torch.from_numpy(img)\n",
    "    img_tensor = img_tensor.to(device=device, dtype=torch.float32)\n",
    "    pred = net(img_tensor)\n",
    "    pred=np.array(pred.data.cpu()[0][0])# 提取结果\n",
    "    pred[pred>=0.5]=255\n",
    "    pred[pred<0.5]=0\n",
    "    cv2.imwrite(save_res_path, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
