{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前做的GAN生成手写数字生成的数字是随机的，没法指定生成哪几个数字。\n",
    "\n",
    "cGAN（conditional Generative Adversarial Nets），条件生成对抗网络，落通过添加限制条件，来控制GAN生成数据的类别。\n",
    "\n",
    "参考资料：https://blog.csdn.net/Andrewseu/article/details/78260193\n",
    "\n",
    "参考代码：https://github.com/arturml/mnist-cgan/blob/master/mnist-cgan.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from torch import autograd\n",
    "from torch.autograd import Variable\n",
    "from torchvision.utils import make_grid\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # https://blog.csdn.net/qq_31829611/article/details/90200694\n",
    "    transforms.Normalize(mean=(0.5, ), std=(0.5, ))\n",
    "])\n",
    "BATCH_SIZE = 32\n",
    "mnist = torchvision.datasets.MNIST(root=r'D:\\_workPlace\\Book\\AI\\CV\\HandwrittenDigitRecognition\\MNIST_DATA',\n",
    "                                   train=True,\n",
    "                                   download=True,\n",
    "                                   transform=transform)\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                         batch_size=BATCH_SIZE,\n",
    "                                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # https://blog.csdn.net/tommorrow12/article/details/80896331\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            # 28*28+10--> 1024\n",
    "            nn.Linear(794, 1024),\n",
    "            # LeakyReLU激活\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # 30%随机置零\n",
    "            nn.Dropout(0.3),\n",
    "            # 1024 --> 512\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            # 512 --> 256\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            # 256 --> 1\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        x = x.view(x.size(0), 784)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([x, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.squeeze() # https://blog.csdn.net/flysky_jay/article/details/81607289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.label_emb = nn.Embedding(10, 10)\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(110, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 784),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "    \n",
    "    def forward(self, z, labels):\n",
    "        z = z.view(z.size(0), 100)\n",
    "        c = self.label_emb(labels)\n",
    "        x = torch.cat([z, c], 1)\n",
    "        out = self.model(x)\n",
    "        return out.view(x.size(0), 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lr = 1e-4 # learning rate\n",
    "D = Discriminator()\n",
    "G = Generator()\n",
    "loss_func = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(D.parameters(), lr=lr)\n",
    "g_optimizer = torch.optim.Adam(G.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_train_step(batch_size, discriminator, generator, g_optimizer, loss_func):\n",
    "    g_optimizer.zero_grad()\n",
    "    z = Variable(torch.randn(batch_size, 100)).to(device)\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0, 10, batch_size))).to(device)\n",
    "    fake_images = generator(z, fake_labels)\n",
    "    validity = discriminator(fake_images, fake_labels)\n",
    "    g_loss = loss_func(validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    g_loss.backward()\n",
    "    g_optimizer.step()\n",
    "    return g_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def  discriminator_train_step(batch_size, discriminator, generator, d_optimizer, loss_func, real_images, labels):\n",
    "    d_optimizer.zero_grad()\n",
    "    # train with real images\n",
    "    real_validity = discriminator(real_images, labels)\n",
    "    real_loss = loss_func(real_validity, Variable(torch.ones(batch_size)).to(device))\n",
    "    # train with fake images\n",
    "    z = Variable(torch.randn(batch_size, 100)).to(device)\n",
    "    fake_labels = Variable(torch.LongTensor(np.random.randint(0,10, batch_size))).to(device)\n",
    "    fake_images=generator(z, fake_labels)\n",
    "    fake_validity = discriminator(fake_images, fake_labels)\n",
    "    fake_loss = loss_func(fake_validity, Variable(torch.zeros(batch_size)))\n",
    "    \n",
    "    d_loss = real_loss+fake_loss\n",
    "    d_loss.backward()\n",
    "    d_optimizer.step()\n",
    "    return d_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ", g_loss:1.7283728122711182, d_loss:0.5969628095626831\n",
      "step:15400, g_loss:2.3766238689422607, d_loss:0.5354121923446655\n",
      "step:15600, g_loss:2.371612071990967, d_loss:0.469868540763855\n",
      "step:15800, g_loss:1.2877240180969238, d_loss:0.39443671703338623\n",
      "step:16000, g_loss:2.4129555225372314, d_loss:0.655976414680481\n",
      "step:16200, g_loss:2.3533544540405273, d_loss:0.6644318103790283\n",
      "step:16400, g_loss:2.071227550506592, d_loss:0.7078574895858765\n",
      "step:16600, g_loss:1.6353187561035156, d_loss:0.6042506098747253\n",
      "step:16800, g_loss:3.0466227531433105, d_loss:0.7085921764373779\n",
      "Starting epoch 9...\n",
      "step:17000, g_loss:1.7709468603134155, d_loss:0.9191223382949829\n",
      "step:17200, g_loss:2.1654536724090576, d_loss:0.7638471722602844\n",
      "step:17400, g_loss:1.1244697570800781, d_loss:1.030300259590149\n",
      "step:17600, g_loss:1.9962244033813477, d_loss:0.6472523212432861\n",
      "step:17800, g_loss:1.6557791233062744, d_loss:0.882902979850769\n",
      "step:18000, g_loss:1.5269957780838013, d_loss:0.7492475509643555\n",
      "step:18200, g_loss:2.0921175479888916, d_loss:0.8829704523086548\n",
      "step:18400, g_loss:1.7195152044296265, d_loss:0.8359484076499939\n",
      "step:18600, g_loss:1.7694122791290283, d_loss:0.871448814868927\n",
      "Starting epoch 10...\n",
      "step:18800, g_loss:1.995142936706543, d_loss:1.129031777381897\n",
      "step:19000, g_loss:1.7455883026123047, d_loss:0.7870523929595947\n",
      "step:19200, g_loss:1.4149069786071777, d_loss:0.9764094352722168\n",
      "step:19400, g_loss:1.584047794342041, d_loss:0.7288689613342285\n",
      "step:19600, g_loss:2.1013429164886475, d_loss:0.6896533966064453\n",
      "step:19800, g_loss:1.8471579551696777, d_loss:0.6035739183425903\n",
      "step:20000, g_loss:2.032552719116211, d_loss:0.6908485889434814\n",
      "step:20200, g_loss:1.6783483028411865, d_loss:0.6462486982345581\n",
      "step:20400, g_loss:1.7494033575057983, d_loss:0.8796240091323853\n",
      "step:20600, g_loss:1.7977415323257446, d_loss:0.7952920794487\n",
      "Starting epoch 11...\n",
      "step:20800, g_loss:2.1507434844970703, d_loss:0.6450722217559814\n",
      "step:21000, g_loss:1.219549536705017, d_loss:0.9318695068359375\n",
      "step:21200, g_loss:1.338805913925171, d_loss:1.0324370861053467\n",
      "step:21400, g_loss:1.312975287437439, d_loss:0.7961041331291199\n",
      "step:21600, g_loss:1.0181211233139038, d_loss:1.0736937522888184\n",
      "step:21800, g_loss:1.5739065408706665, d_loss:0.9768106937408447\n",
      "step:22000, g_loss:2.0955867767333984, d_loss:1.2294270992279053\n",
      "step:22200, g_loss:1.8157014846801758, d_loss:0.8850315809249878\n",
      "step:22400, g_loss:1.1866896152496338, d_loss:0.9499971270561218\n",
      "Starting epoch 12...\n",
      "step:22600, g_loss:1.359618902206421, d_loss:1.0781663656234741\n",
      "step:22800, g_loss:1.3643603324890137, d_loss:0.8562692403793335\n",
      "step:23000, g_loss:1.5049811601638794, d_loss:1.1495803594589233\n",
      "step:23200, g_loss:1.2105056047439575, d_loss:1.0397655963897705\n",
      "step:23400, g_loss:1.8353368043899536, d_loss:0.7681498527526855\n",
      "step:23600, g_loss:1.5107877254486084, d_loss:0.745674729347229\n",
      "step:23800, g_loss:1.8431603908538818, d_loss:1.1701334714889526\n",
      "step:24000, g_loss:1.7404530048370361, d_loss:1.0889537334442139\n",
      "step:24200, g_loss:1.610396146774292, d_loss:1.0057076215744019\n",
      "Starting epoch 13...\n",
      "step:24400, g_loss:1.3350170850753784, d_loss:0.8323545455932617\n",
      "step:24600, g_loss:1.4173766374588013, d_loss:0.935019314289093\n",
      "step:24800, g_loss:1.5809885263442993, d_loss:0.799593985080719\n",
      "step:25000, g_loss:1.3296494483947754, d_loss:1.158412218093872\n",
      "step:25200, g_loss:1.4441087245941162, d_loss:1.2036913633346558\n",
      "step:25400, g_loss:1.0180275440216064, d_loss:1.1257476806640625\n",
      "step:25600, g_loss:1.5590994358062744, d_loss:0.7924341559410095\n",
      "step:25800, g_loss:1.1524748802185059, d_loss:0.9811500310897827\n",
      "step:26000, g_loss:1.3474555015563965, d_loss:1.00460946559906\n",
      "step:26200, g_loss:1.5193902254104614, d_loss:0.9440006613731384\n",
      "Starting epoch 14...\n",
      "step:26400, g_loss:1.3628716468811035, d_loss:1.0552713871002197\n",
      "step:26600, g_loss:0.799996018409729, d_loss:1.4198744297027588\n",
      "step:26800, g_loss:1.5526113510131836, d_loss:1.0620635747909546\n",
      "step:27000, g_loss:1.5680677890777588, d_loss:1.008909821510315\n",
      "step:27200, g_loss:1.2820534706115723, d_loss:0.8652764558792114\n",
      "step:27400, g_loss:1.415656328201294, d_loss:1.0543324947357178\n",
      "step:27600, g_loss:1.5364744663238525, d_loss:1.1826393604278564\n",
      "step:27800, g_loss:1.361625075340271, d_loss:1.196326732635498\n",
      "step:28000, g_loss:1.3787386417388916, d_loss:0.9011168479919434\n",
      "Starting epoch 15...\n",
      "step:28200, g_loss:2.0368900299072266, d_loss:1.0737557411193848\n",
      "step:28400, g_loss:1.596569538116455, d_loss:1.025362491607666\n",
      "step:28600, g_loss:1.2410595417022705, d_loss:1.233322024345398\n",
      "step:28800, g_loss:1.2805763483047485, d_loss:1.0717945098876953\n",
      "step:29000, g_loss:1.284392237663269, d_loss:0.8693559169769287\n",
      "step:29200, g_loss:1.2260000705718994, d_loss:0.9931332468986511\n",
      "step:29400, g_loss:0.966895341873169, d_loss:0.9821094870567322\n",
      "step:29600, g_loss:1.437732219696045, d_loss:1.0096657276153564\n",
      "step:29800, g_loss:1.3023402690887451, d_loss:1.179032564163208\n",
      "step:30000, g_loss:1.1985735893249512, d_loss:1.0651594400405884\n",
      "Starting epoch 16...\n",
      "step:30200, g_loss:1.4506144523620605, d_loss:1.0002529621124268\n",
      "step:30400, g_loss:1.2794440984725952, d_loss:1.0773720741271973\n",
      "step:30600, g_loss:1.2331228256225586, d_loss:1.1370444297790527\n",
      "step:30800, g_loss:0.9253445863723755, d_loss:1.260152816772461\n",
      "step:31000, g_loss:1.1780129671096802, d_loss:0.9001854062080383\n",
      "step:31200, g_loss:1.051469087600708, d_loss:1.0894947052001953\n",
      "step:31400, g_loss:1.3338768482208252, d_loss:1.08072829246521\n",
      "step:31600, g_loss:1.0987777709960938, d_loss:1.2039194107055664\n",
      "step:31800, g_loss:0.9780250787734985, d_loss:1.0334669351577759\n",
      "Starting epoch 17...\n",
      "step:32000, g_loss:1.4226658344268799, d_loss:0.7578940391540527\n",
      "step:32200, g_loss:1.6622145175933838, d_loss:0.9055978059768677\n",
      "step:32400, g_loss:1.435128927230835, d_loss:0.906410813331604\n",
      "step:32600, g_loss:1.2828983068466187, d_loss:1.1196699142456055\n",
      "step:32800, g_loss:1.1871970891952515, d_loss:1.103530764579773\n",
      "step:33000, g_loss:1.3078967332839966, d_loss:1.2591959238052368\n",
      "step:33200, g_loss:1.5028190612792969, d_loss:1.2031867504119873\n",
      "step:33400, g_loss:1.193666934967041, d_loss:1.015334963798523\n",
      "step:33600, g_loss:1.3571884632110596, d_loss:1.1379414796829224\n",
      "Starting epoch 18...\n",
      "step:33800, g_loss:1.4362822771072388, d_loss:1.0337644815444946\n",
      "step:34000, g_loss:1.0722802877426147, d_loss:1.0827150344848633\n",
      "step:34200, g_loss:1.2380938529968262, d_loss:0.946762204170227\n",
      "step:34400, g_loss:1.4713335037231445, d_loss:1.1412403583526611\n",
      "step:34600, g_loss:1.0783933401107788, d_loss:1.1240228414535522\n",
      "step:34800, g_loss:1.0470739603042603, d_loss:1.159106969833374\n",
      "step:35000, g_loss:1.0466911792755127, d_loss:1.0802109241485596\n",
      "step:35200, g_loss:0.9584602117538452, d_loss:1.0149670839309692\n",
      "step:35400, g_loss:1.0089880228042603, d_loss:1.090259313583374\n",
      "step:35600, g_loss:1.1043293476104736, d_loss:1.2310024499893188\n",
      "Starting epoch 19...\n",
      "step:35800, g_loss:0.8340300917625427, d_loss:1.0169299840927124\n",
      "step:36000, g_loss:0.8418480157852173, d_loss:1.194970965385437\n",
      "step:36200, g_loss:0.9559410810470581, d_loss:1.178833246231079\n",
      "step:36400, g_loss:0.9739460349082947, d_loss:1.3761969804763794\n",
      "step:36600, g_loss:1.0055596828460693, d_loss:1.125901222229004\n",
      "step:36800, g_loss:1.211900234222412, d_loss:0.9772686958312988\n",
      "step:37000, g_loss:1.0346165895462036, d_loss:1.126720905303955\n",
      "step:37200, g_loss:1.4717820882797241, d_loss:0.869295597076416\n",
      "step:37400, g_loss:0.9703595042228699, d_loss:1.0887701511383057\n",
      "Starting epoch 20...\n",
      "step:37600, g_loss:0.910239040851593, d_loss:1.1504528522491455\n",
      "step:37800, g_loss:1.1000499725341797, d_loss:1.1555051803588867\n",
      "step:38000, g_loss:0.9597693681716919, d_loss:1.150374174118042\n",
      "step:38200, g_loss:0.8804107308387756, d_loss:1.053088665008545\n",
      "step:38400, g_loss:1.0498299598693848, d_loss:0.9525207877159119\n",
      "step:38600, g_loss:0.937065601348877, d_loss:1.2170634269714355\n",
      "step:38800, g_loss:1.2881033420562744, d_loss:1.1267085075378418\n",
      "step:39000, g_loss:1.1639747619628906, d_loss:1.0647919178009033\n",
      "step:39200, g_loss:1.08701753616333, d_loss:1.1482946872711182\n",
      "Starting epoch 21...\n",
      "step:39400, g_loss:0.9862363338470459, d_loss:1.1704461574554443\n",
      "step:39600, g_loss:0.8571174740791321, d_loss:1.3005926609039307\n",
      "step:39800, g_loss:0.88970947265625, d_loss:1.3840868473052979\n",
      "step:40000, g_loss:0.9709621667861938, d_loss:1.1732501983642578\n",
      "step:40200, g_loss:1.3122797012329102, d_loss:0.9899217486381531\n",
      "step:40400, g_loss:1.2937119007110596, d_loss:1.058056354522705\n",
      "step:40600, g_loss:0.812080979347229, d_loss:1.0908722877502441\n",
      "step:40800, g_loss:0.9735089540481567, d_loss:1.2094035148620605\n",
      "step:41000, g_loss:1.0227593183517456, d_loss:1.126467227935791\n",
      "step:41200, g_loss:0.8694787621498108, d_loss:1.201568841934204\n",
      "Starting epoch 22...\n",
      "step:41400, g_loss:1.1591579914093018, d_loss:1.099687099456787\n",
      "step:41600, g_loss:1.0759048461914062, d_loss:1.358599305152893\n",
      "step:41800, g_loss:1.0839080810546875, d_loss:1.0154857635498047\n",
      "step:42000, g_loss:1.0276522636413574, d_loss:1.0541930198669434\n",
      "step:42200, g_loss:1.1863499879837036, d_loss:1.2871880531311035\n",
      "step:42400, g_loss:1.1102821826934814, d_loss:1.0263876914978027\n",
      "step:42600, g_loss:0.8608520030975342, d_loss:1.1357924938201904\n",
      "step:42800, g_loss:0.9740236401557922, d_loss:1.1398102045059204\n",
      "step:43000, g_loss:0.9954403638839722, d_loss:1.1635112762451172\n",
      "Starting epoch 23...\n",
      "step:43200, g_loss:1.2863596677780151, d_loss:1.26820707321167\n",
      "step:43400, g_loss:1.2753140926361084, d_loss:1.1059083938598633\n",
      "step:43600, g_loss:1.0713937282562256, d_loss:1.0744454860687256\n",
      "step:43800, g_loss:1.1099951267242432, d_loss:1.1918054819107056\n",
      "step:44000, g_loss:0.9363883137702942, d_loss:1.1584469079971313\n",
      "step:44200, g_loss:1.1356271505355835, d_loss:1.0819703340530396\n",
      "step:44400, g_loss:1.0915019512176514, d_loss:1.133686900138855\n",
      "step:44600, g_loss:1.1424072980880737, d_loss:1.167858600616455\n",
      "step:44800, g_loss:1.460763692855835, d_loss:1.1416354179382324\n",
      "step:45000, g_loss:0.9314273595809937, d_loss:1.1900488138198853\n",
      "Starting epoch 24...\n",
      "step:45200, g_loss:1.2253961563110352, d_loss:1.2315223217010498\n",
      "step:45400, g_loss:1.0575896501541138, d_loss:1.0910365581512451\n",
      "step:45600, g_loss:1.1278966665267944, d_loss:1.3366196155548096\n",
      "step:45800, g_loss:0.7142387628555298, d_loss:1.3077564239501953\n",
      "step:46000, g_loss:1.0680162906646729, d_loss:1.1551389694213867\n",
      "step:46200, g_loss:0.9259697198867798, d_loss:1.2228939533233643\n",
      "step:46400, g_loss:1.2530393600463867, d_loss:1.1382956504821777\n",
      "step:46600, g_loss:1.3608907461166382, d_loss:1.2088643312454224\n",
      "step:46800, g_loss:0.8972619771957397, d_loss:1.34147047996521\n",
      "Starting epoch 25...\n",
      "step:47000, g_loss:1.1609758138656616, d_loss:1.17557692527771\n",
      "step:47200, g_loss:1.1187996864318848, d_loss:1.231939435005188\n",
      "step:47400, g_loss:0.7937489748001099, d_loss:1.1503779888153076\n",
      "step:47600, g_loss:0.8823931217193604, d_loss:1.193835973739624\n",
      "step:47800, g_loss:1.172556757926941, d_loss:1.1554656028747559\n",
      "step:48000, g_loss:1.0901904106140137, d_loss:1.2755913734436035\n",
      "step:48200, g_loss:0.8804567456245422, d_loss:1.2967698574066162\n",
      "step:48400, g_loss:0.8221747875213623, d_loss:1.217883825302124\n",
      "step:48600, g_loss:0.7896501421928406, d_loss:1.2134056091308594\n",
      "Starting epoch 26...\n",
      "step:48800, g_loss:0.8411692976951599, d_loss:1.2057085037231445\n",
      "step:49000, g_loss:1.087052822113037, d_loss:1.2392665147781372\n",
      "step:49200, g_loss:0.939443051815033, d_loss:1.3743319511413574\n",
      "step:49400, g_loss:0.968399167060852, d_loss:1.1098202466964722\n",
      "step:49600, g_loss:1.048014521598816, d_loss:1.2405470609664917\n",
      "step:49800, g_loss:0.7769954800605774, d_loss:1.3202099800109863\n",
      "step:50000, g_loss:1.1855477094650269, d_loss:1.1451616287231445\n",
      "step:50200, g_loss:0.9139168858528137, d_loss:1.23970365524292\n",
      "step:50400, g_loss:1.3169366121292114, d_loss:1.0046743154525757\n",
      "step:50600, g_loss:1.0379775762557983, d_loss:1.127078890800476\n",
      "Starting epoch 27...\n",
      "step:50800, g_loss:0.9618356227874756, d_loss:1.2847237586975098\n",
      "step:51000, g_loss:0.9354311227798462, d_loss:1.4814527034759521\n",
      "step:51200, g_loss:1.1341511011123657, d_loss:1.3034319877624512\n",
      "step:51400, g_loss:0.9296339154243469, d_loss:1.096069097518921\n",
      "step:51600, g_loss:1.1480891704559326, d_loss:1.3045086860656738\n",
      "step:51800, g_loss:1.010594129562378, d_loss:1.3219044208526611\n",
      "step:52000, g_loss:1.161474347114563, d_loss:0.9520121812820435\n",
      "step:52200, g_loss:0.8350540399551392, d_loss:1.063894271850586\n",
      "step:52400, g_loss:0.8808643817901611, d_loss:1.2431087493896484\n",
      "Starting epoch 28...\n",
      "step:52600, g_loss:0.9351317882537842, d_loss:1.3048075437545776\n",
      "step:52800, g_loss:0.9844779968261719, d_loss:1.275129795074463\n",
      "step:53000, g_loss:0.930929958820343, d_loss:1.281728982925415\n",
      "step:53200, g_loss:1.1897790431976318, d_loss:1.1705527305603027\n",
      "step:53400, g_loss:1.0957344770431519, d_loss:1.0314548015594482\n",
      "step:53600, g_loss:0.8238711953163147, d_loss:1.2271100282669067\n",
      "step:53800, g_loss:0.9946386814117432, d_loss:1.1780211925506592\n",
      "step:54000, g_loss:1.0153656005859375, d_loss:1.1410491466522217\n",
      "step:54200, g_loss:1.138458013534546, d_loss:1.2123534679412842\n",
      "Starting epoch 29...\n",
      "step:54400, g_loss:0.7985979914665222, d_loss:1.2879366874694824\n",
      "step:54600, g_loss:1.1446006298065186, d_loss:1.3062474727630615\n",
      "step:54800, g_loss:0.738416314125061, d_loss:1.3504756689071655\n",
      "step:55000, g_loss:0.8424639105796814, d_loss:1.073850154876709\n",
      "step:55200, g_loss:0.7104573845863342, d_loss:1.268122673034668\n",
      "step:55400, g_loss:0.9682581424713135, d_loss:1.2032806873321533\n",
      "step:55600, g_loss:1.0357716083526611, d_loss:1.222123384475708\n",
      "step:55800, g_loss:0.9620136022567749, d_loss:1.269261360168457\n",
      "step:56000, g_loss:0.7839419841766357, d_loss:1.2755720615386963\n",
      "step:56200, g_loss:0.9920969009399414, d_loss:1.3655214309692383\n",
      "Starting epoch 30...\n",
      "step:56400, g_loss:1.030081868171692, d_loss:1.1119508743286133\n",
      "step:56600, g_loss:0.8483786582946777, d_loss:1.4504947662353516\n",
      "step:56800, g_loss:0.9185078144073486, d_loss:1.1632959842681885\n",
      "step:57000, g_loss:0.9167381525039673, d_loss:1.3671250343322754\n",
      "step:57200, g_loss:0.9516589641571045, d_loss:1.22543466091156\n",
      "step:57400, g_loss:0.7626922130584717, d_loss:1.1537902355194092\n",
      "step:57600, g_loss:1.0836488008499146, d_loss:1.019932746887207\n",
      "step:57800, g_loss:0.8735368251800537, d_loss:1.2898919582366943\n",
      "step:58000, g_loss:1.087630033493042, d_loss:1.3864630460739136\n",
      "Starting epoch 31...\n",
      "step:58200, g_loss:1.0698732137680054, d_loss:1.054836630821228\n",
      "step:58400, g_loss:1.16367506980896, d_loss:1.1130069494247437\n",
      "step:58600, g_loss:0.9898208379745483, d_loss:1.0615408420562744\n",
      "step:58800, g_loss:0.6693142652511597, d_loss:1.4692130088806152\n",
      "step:59000, g_loss:0.8802729845046997, d_loss:1.1514880657196045\n",
      "step:59200, g_loss:0.8631384372711182, d_loss:1.1797831058502197\n",
      "step:59400, g_loss:1.105064868927002, d_loss:1.258523941040039\n",
      "step:59600, g_loss:0.9492955803871155, d_loss:1.074955940246582\n",
      "step:59800, g_loss:0.8008105158805847, d_loss:1.279663324356079\n",
      "step:60000, g_loss:0.9001237154006958, d_loss:1.1395870447158813\n",
      "Starting epoch 32...\n",
      "step:60200, g_loss:1.0065078735351562, d_loss:1.1044838428497314\n",
      "step:60400, g_loss:0.806678056716919, d_loss:1.2471909523010254\n",
      "step:60600, g_loss:0.8133952021598816, d_loss:1.2168917655944824\n",
      "step:60800, g_loss:0.7643671035766602, d_loss:1.378939151763916\n",
      "step:61000, g_loss:0.8512109518051147, d_loss:1.330998420715332\n",
      "step:61200, g_loss:1.1334419250488281, d_loss:1.192148208618164\n",
      "step:61400, g_loss:1.0256555080413818, d_loss:1.160158634185791\n",
      "step:61600, g_loss:0.7643232345581055, d_loss:1.2441326379776\n",
      "step:61800, g_loss:0.9220512509346008, d_loss:1.297203540802002\n",
      "Starting epoch 33...\n",
      "step:62000, g_loss:0.8485733270645142, d_loss:1.1095573902130127\n",
      "step:62200, g_loss:0.7944768667221069, d_loss:1.429039478302002\n",
      "step:62400, g_loss:1.0846260786056519, d_loss:1.243431568145752\n",
      "step:62600, g_loss:0.9501943588256836, d_loss:1.1451479196548462\n",
      "step:62800, g_loss:0.827059268951416, d_loss:1.2693005800247192\n",
      "step:63000, g_loss:0.8458755016326904, d_loss:1.2935309410095215\n",
      "step:63200, g_loss:1.0358357429504395, d_loss:1.1844279766082764\n",
      "step:63400, g_loss:0.8893731832504272, d_loss:1.2166712284088135\n",
      "step:63600, g_loss:0.8948084115982056, d_loss:1.3230512142181396\n",
      "Starting epoch 34...\n",
      "step:63800, g_loss:0.8914706110954285, d_loss:1.295667052268982\n",
      "step:64000, g_loss:0.9523242115974426, d_loss:1.2895290851593018\n",
      "step:64200, g_loss:0.987686276435852, d_loss:1.0681943893432617\n",
      "step:64400, g_loss:0.9032193422317505, d_loss:1.1907479763031006\n",
      "step:64600, g_loss:0.8001852035522461, d_loss:1.2198460102081299\n",
      "step:64800, g_loss:1.2045800685882568, d_loss:1.0929419994354248\n",
      "step:65000, g_loss:0.8857908844947815, d_loss:1.1787242889404297\n",
      "step:65200, g_loss:0.9777132272720337, d_loss:1.240822434425354\n",
      "step:65400, g_loss:0.997229814529419, d_loss:1.1292024850845337\n",
      "step:65600, g_loss:1.0659984350204468, d_loss:1.2934777736663818\n",
      "Starting epoch 35...\n",
      "step:65800, g_loss:0.9762574434280396, d_loss:1.157806158065796\n",
      "step:66000, g_loss:1.0123111009597778, d_loss:1.2298412322998047\n",
      "step:66200, g_loss:0.7764713764190674, d_loss:1.3213107585906982\n",
      "step:66400, g_loss:0.9213640689849854, d_loss:1.2290246486663818\n",
      "step:66600, g_loss:0.8319156169891357, d_loss:1.372169017791748\n",
      "step:66800, g_loss:0.9433325529098511, d_loss:1.200415849685669\n",
      "step:67000, g_loss:1.0909546613693237, d_loss:1.2417833805084229\n",
      "step:67200, g_loss:0.7800650596618652, d_loss:1.222301959991455\n",
      "step:67400, g_loss:1.063325047492981, d_loss:1.1118979454040527\n",
      "Starting epoch 36...\n",
      "step:67600, g_loss:0.9540013670921326, d_loss:1.1448400020599365\n",
      "step:67800, g_loss:0.8907712697982788, d_loss:1.3519365787506104\n",
      "step:68000, g_loss:0.9081258177757263, d_loss:1.2446870803833008\n",
      "step:68200, g_loss:0.8352320194244385, d_loss:1.2207893133163452\n",
      "step:68400, g_loss:0.8995079398155212, d_loss:1.1884171962738037\n",
      "step:68600, g_loss:0.786514163017273, d_loss:1.5603435039520264\n",
      "step:68800, g_loss:0.9551353454589844, d_loss:1.2993946075439453\n",
      "step:69000, g_loss:0.9041541814804077, d_loss:1.461406946182251\n",
      "step:69200, g_loss:0.9495012760162354, d_loss:1.206984043121338\n",
      "Starting epoch 37...\n",
      "step:69400, g_loss:1.0960427522659302, d_loss:1.0776817798614502\n",
      "step:69600, g_loss:0.8299564719200134, d_loss:1.379423975944519\n",
      "step:69800, g_loss:0.8142935633659363, d_loss:1.4301743507385254\n",
      "step:70000, g_loss:0.9482420682907104, d_loss:1.2747597694396973\n",
      "step:70200, g_loss:0.8262411952018738, d_loss:1.232637643814087\n",
      "step:70400, g_loss:0.7901269197463989, d_loss:1.1562490463256836\n",
      "step:70600, g_loss:0.9049239158630371, d_loss:1.121964454650879\n",
      "step:70800, g_loss:0.9371305704116821, d_loss:1.0994608402252197\n",
      "step:71000, g_loss:1.106905221939087, d_loss:1.1918721199035645\n",
      "step:71200, g_loss:0.9105678796768188, d_loss:1.1621627807617188\n",
      "Starting epoch 38...\n",
      "step:71400, g_loss:1.0392650365829468, d_loss:1.1624386310577393\n",
      "step:71600, g_loss:0.8757011890411377, d_loss:1.409737229347229\n",
      "step:71800, g_loss:0.9137338399887085, d_loss:1.2872687578201294\n",
      "step:72000, g_loss:0.777197003364563, d_loss:1.339585304260254\n",
      "step:72200, g_loss:0.7234564423561096, d_loss:1.1394448280334473\n",
      "step:72400, g_loss:0.9131888151168823, d_loss:1.2286368608474731\n",
      "step:72600, g_loss:0.7285332679748535, d_loss:1.3252167701721191\n",
      "step:72800, g_loss:0.8477753400802612, d_loss:1.1798665523529053\n",
      "step:73000, g_loss:0.7947992086410522, d_loss:1.198591947555542\n",
      "Starting epoch 39...\n",
      "step:73200, g_loss:1.0132348537445068, d_loss:1.1870594024658203\n",
      "step:73400, g_loss:0.8816826939582825, d_loss:1.2661925554275513\n",
      "step:73600, g_loss:0.8514502644538879, d_loss:1.3097752332687378\n",
      "step:73800, g_loss:0.8072055578231812, d_loss:1.2867202758789062\n",
      "step:74000, g_loss:0.8560773134231567, d_loss:1.4226316213607788\n",
      "step:74200, g_loss:0.9271485209465027, d_loss:1.2056684494018555\n",
      "step:74400, g_loss:0.7750315070152283, d_loss:1.393873929977417\n",
      "step:74600, g_loss:0.8344548940658569, d_loss:1.2414606809616089\n",
      "step:74800, g_loss:0.7655744552612305, d_loss:1.2556562423706055\n",
      "step:75000, g_loss:0.8163578510284424, d_loss:1.3045430183410645\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "EPOCHS = 40\n",
    "for epoch in range(EPOCHS):\n",
    "    print('Starting epoch {}...'.format(epoch))\n",
    "    for i, (images, labels) in enumerate(data_loader):\n",
    "        step = epoch * len(data_loader)+i+1\n",
    "        real_images = Variable(images).to(device)\n",
    "        labels = Variable(labels).to(device)\n",
    "        \n",
    "        # https://blog.csdn.net/qq_36653505/article/details/84728489\n",
    "        G.train()\n",
    "        d_loss = discriminator_train_step(len(real_images), D, G, d_optimizer, loss_func, real_images, labels)\n",
    "        g_loss = generator_train_step(BATCH_SIZE, D, G, g_optimizer, loss_func)\n",
    "        if step % 200 == 0:\n",
    "            print(\"step:{0}, g_loss:{1}, d_loss:{2}\".format(step, g_loss, d_loss))\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(G.state_dict(), 'cGAN_Model\\generator.pth')\n",
    "torch.save(D.state_dict(), 'cGAN_Model\\discriminator.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "def load_model():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    D = Discriminator() # 不能和类同名\n",
    "    G = Generator()\n",
    "    D.to(device=device)\n",
    "    G.to(device=device)\n",
    "    D.load_state_dict(torch.load('cGAN_Model/discriminator.pth', map_location=device))\n",
    "    G.load_state_dict(torch.load('cGAN_Model/generator.pth', map_location=device))\n",
    "    return G, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <defs>\r\n  <style type=\"text/css\">\r\n*{stroke-linecap:butt;stroke-linejoin:round;}\r\n  </style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pc7df17b666)\">\r\n    <image height=\"218\" id=\"image23aeaa6f62\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\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\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"m7afa7fd349\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m7afa7fd349\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <defs>\r\n       <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n      </defs>\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m7afa7fd349\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <defs>\r\n       <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n      </defs>\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m7afa7fd349\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <defs>\r\n       <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n      </defs>\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m7afa7fd349\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m7afa7fd349\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <defs>\r\n       <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n      </defs>\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m7afa7fd349\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"ma7dbd02630\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma7dbd02630\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma7dbd02630\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma7dbd02630\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma7dbd02630\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma7dbd02630\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#ma7dbd02630\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pc7df17b666\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "# test\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z = Variable(torch.randn(1, 100)).to(device)\n",
    "label = torch.LongTensor([0]).to(device)\n",
    "G, D = load_model()\n",
    "img = G(z, label).data.to(device)\n",
    "img = 0.5*img+0.5\n",
    "c=transforms.ToPILImage()(img)\n",
    "plt.imshow(c)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}